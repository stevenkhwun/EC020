---
title: 'Heteroskedasticity'
date: "2023/6/22"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


> Learning points:
>
> * calculate heteroskedasticity robust standard errors using `coeftest()` function
> * F-test under heteroskedasticity assumption using `linearHypothesis()` function
> * use `ggplot()` function of the `ggplot2` package

This document is adapted from the article [How to Perform Weighted Least Squares Regression in R](https://www.statology.org/weighted-least-squares-in-r/) on statology.org.



# Create the Data

The following code creates a data frame that contains the number of hours studied and the corresponding exam score for 16 students:

```{r}
df <- data.frame(hours=c(1,1,2,2,2,3,4,4,4,5,5,5,6,6,7,8),
                 score=c(48,78,72,70,66,92,93,75,75,80,95,97,90,96,99,99))
```

# Perform Linear Regression

```{r}
# fit simple linear regression model
model <- lm(score ~ hours, data=df)
summary(model)
```

# Test for Heteroscedasticity

Next, we’ll create a residual vs. fitted values plot to visually check for heteroscedasticity:

```{r}
# create residual vs. fitted plot
plot(fitted(model), resid(model), xlab="Fitted Values", ylab="Residuals")
abline(0,0)        # add a horizontal line at 0
```

We can see from the plot that the residuals exhibit a “cone” shape – they’re not distributed with equal variance throughout the plot. 

To formally test for heteroscedasticity, we can perform a Breusch-Pagan test:

```{r message=FALSE}
# perform Breusch-Pagan test
library(lmtest)     # load the required package
bptest(model)       # perform Breusch-Pagan test
```

The Breusch-Pagan test uses the following null and alternative hypotheses:

* Null Hypothesis ($H_0$): Homoscedasticity is present (the residuals are distributed with equal variance)
* Alternative Hypothesis ($H_a$): Heteroscedasticity is present (the residuals are not distributed with equal variance)

Since the p-value from the test is $0.0466$ we will reject the null hypothesis and conclude that heteroscedasticity is a problem in this model.

# Perform Weighted Least Squares Regression

Since heteroscedasticity is present, we will perform weighted least squares by defining the weights in such a way that the observations with lower variance are given more weight:

```{r}
# define weights to use
wt <- 1 / lm(abs(model$residuals) ~ model$fitted.values)$fitted.values^2
```

```{r}
# perform weighted least squares regression
wls_model <- lm(score ~ hours, data=df, weights=wt)
summary(wls_model)
```

From the output we can see that the coefficient estimate for the predictor variable hours changed a bit and the overall fit of the model improved.

The weighted least squares model has a residual standard error of $1.199$ compared to $9.224$ in the original simple linear regression model.

This indicates that the predicted values produced by the weighted least squares model are much closer to the actual observations compared to the predicted values produced by the simple linear regression model.

The weighted least squares model also has an R-squared of $0.6762$ compared to $0.6296$ in the original simple linear regression model.

This indicates that the weighted least squares model is able to explain more of the variance in exam scores compared to the simple linear regression model.

These metrics indicate that the weighted least squares model offers a better fit to the data compared to the simple linear regression model.